{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.precision = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>precision_at_1</th>\n",
       "      <th>mean_average_precision</th>\n",
       "      <th>recall_at_k</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>ausc</th>\n",
       "      <th>ece</th>\n",
       "      <th>precision_at_1_expected</th>\n",
       "      <th>mean_average_precision_expected</th>\n",
       "      <th>recall_at_k_expected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latent_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7579 ± 0.002</td>\n",
       "      <td>0.8085 ± 0.0016</td>\n",
       "      <td>0.9149 ± 0.0019</td>\n",
       "      <td>0.9888 ± 0.0002</td>\n",
       "      <td>0.9872 ± 0.0003</td>\n",
       "      <td>0.8587 ± 0.003</td>\n",
       "      <td>0.0425 ± 0.0038</td>\n",
       "      <td>0.6793 ± 0.0346</td>\n",
       "      <td>0.7519 ± 0.0208</td>\n",
       "      <td>0.9029 ± 0.0291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.9068 ± 0.0008</td>\n",
       "      <td>0.9192 ± 0.0005</td>\n",
       "      <td>0.947 ± 0.0014</td>\n",
       "      <td>0.9667 ± 0.0002</td>\n",
       "      <td>0.9612 ± 0.0006</td>\n",
       "      <td>0.9618 ± 0.0004</td>\n",
       "      <td>0.0862 ± 0.0019</td>\n",
       "      <td>0.9015 ± 0.0091</td>\n",
       "      <td>0.9144 ± 0.0046</td>\n",
       "      <td>0.9435 ± 0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.9098 ± 0.0013</td>\n",
       "      <td>0.9214 ± 0.0005</td>\n",
       "      <td>0.9468 ± 0.0007</td>\n",
       "      <td>0.9592 ± 0.0007</td>\n",
       "      <td>0.9518 ± 0.0008</td>\n",
       "      <td>0.9647 ± 0.0004</td>\n",
       "      <td>0.1317 ± 0.0043</td>\n",
       "      <td>0.8984 ± 0.0057</td>\n",
       "      <td>0.9121 ± 0.0027</td>\n",
       "      <td>0.9474 ± 0.0048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric        precision_at_1 mean_average_precision      recall_at_k  \\\n",
       "latent_size                                                            \n",
       "2             0.7579 ± 0.002        0.8085 ± 0.0016  0.9149 ± 0.0019   \n",
       "16           0.9068 ± 0.0008        0.9192 ± 0.0005   0.947 ± 0.0014   \n",
       "32           0.9098 ± 0.0013        0.9214 ± 0.0005  0.9468 ± 0.0007   \n",
       "\n",
       "metric                 auroc            auprc             ausc  \\\n",
       "latent_size                                                      \n",
       "2            0.9888 ± 0.0002  0.9872 ± 0.0003   0.8587 ± 0.003   \n",
       "16           0.9667 ± 0.0002  0.9612 ± 0.0006  0.9618 ± 0.0004   \n",
       "32           0.9592 ± 0.0007  0.9518 ± 0.0008  0.9647 ± 0.0004   \n",
       "\n",
       "metric                   ece precision_at_1_expected  \\\n",
       "latent_size                                            \n",
       "2            0.0425 ± 0.0038         0.6793 ± 0.0346   \n",
       "16           0.0862 ± 0.0019         0.9015 ± 0.0091   \n",
       "32           0.1317 ± 0.0043         0.8984 ± 0.0057   \n",
       "\n",
       "metric      mean_average_precision_expected recall_at_k_expected  \n",
       "latent_size                                                       \n",
       "2                           0.7519 ± 0.0208      0.9029 ± 0.0291  \n",
       "16                          0.9144 ± 0.0046      0.9435 ± 0.0025  \n",
       "32                          0.9121 ± 0.0027      0.9474 ± 0.0048  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../outputs/PostHoc/figures/FashionMNIST/fixed/metrics.csv\",\n",
    "                 header=None,\n",
    "                 names=[\"metric\", \"value\", \"latent_size\"],\n",
    "                 dtype={\"metric\": str, \"value\": float, \"latent_size\": int})\n",
    "\n",
    "df\\\n",
    "    .sort_values(by=[\"latent_size\", \"metric\"])\\\n",
    "    .groupby([\"latent_size\", \"metric\"]).agg([\"mean\", \"std\"])\n",
    "\n",
    "df = df\\\n",
    "    .sort_values(by=[\"latent_size\", \"metric\"])\\\n",
    "    .groupby([\"latent_size\", \"metric\"]).agg([\"mean\", \"std\"])\\\n",
    "\n",
    "df.columns = df.columns.to_flat_index()\n",
    "\n",
    "df = df.assign(val=lambda x: x[(\"value\", \"mean\")].round(4).apply(str) + \" ± \" + x[(\"value\", \"std\")].round(4).apply(str))\\\n",
    "    .drop([(\"value\", \"mean\"), (\"value\", \"std\")], axis=1)\\\n",
    "    .reset_index()\\\n",
    "    .pivot(index=\"latent_size\", columns=\"metric\", values=\"val\")\n",
    "\n",
    "cols = [\"precision_at_1\", \"mean_average_precision\", \"recall_at_k\", \"auroc\", \"auprc\", \"ausc\", \"ece\", \"precision_at_1_expected\", \"mean_average_precision_expected\", \"recall_at_k_expected\"]\n",
    "df[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>precision_at_1</th>\n",
       "      <th>mean_average_precision</th>\n",
       "      <th>recall_at_k</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>ausc</th>\n",
       "      <th>ece</th>\n",
       "      <th>precision_at_1_expected</th>\n",
       "      <th>mean_average_precision_expected</th>\n",
       "      <th>recall_at_k_expected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latent_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5891 ± 0.0051</td>\n",
       "      <td>0.6543 ± 0.0035</td>\n",
       "      <td>0.7853 ± 0.0031</td>\n",
       "      <td>0.6097 ± 0.0231</td>\n",
       "      <td>0.7508 ± 0.018</td>\n",
       "      <td>0.77 ± 0.005</td>\n",
       "      <td>0.128 ± 0.0059</td>\n",
       "      <td>0.6297 ± 0.0294</td>\n",
       "      <td>0.6534 ± 0.0126</td>\n",
       "      <td>0.7013 ± 0.0107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.5958 ± 0.0045</td>\n",
       "      <td>0.6579 ± 0.0022</td>\n",
       "      <td>0.7838 ± 0.0041</td>\n",
       "      <td>0.6337 ± 0.0129</td>\n",
       "      <td>0.7661 ± 0.0088</td>\n",
       "      <td>0.7709 ± 0.0019</td>\n",
       "      <td>0.2027 ± 0.0095</td>\n",
       "      <td>0.6374 ± 0.0063</td>\n",
       "      <td>0.649 ± 0.0075</td>\n",
       "      <td>0.6824 ± 0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.6178 ± 0.0041</td>\n",
       "      <td>0.6603 ± 0.0036</td>\n",
       "      <td>0.747 ± 0.0039</td>\n",
       "      <td>0.5568 ± 0.0145</td>\n",
       "      <td>0.712 ± 0.009</td>\n",
       "      <td>0.7647 ± 0.0026</td>\n",
       "      <td>0.2152 ± 0.0086</td>\n",
       "      <td>0.522 ± 0.0299</td>\n",
       "      <td>0.55 ± 0.0209</td>\n",
       "      <td>0.6124 ± 0.0222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric        precision_at_1 mean_average_precision      recall_at_k  \\\n",
       "latent_size                                                            \n",
       "16           0.5891 ± 0.0051        0.6543 ± 0.0035  0.7853 ± 0.0031   \n",
       "32           0.5958 ± 0.0045        0.6579 ± 0.0022  0.7838 ± 0.0041   \n",
       "64           0.6178 ± 0.0041        0.6603 ± 0.0036   0.747 ± 0.0039   \n",
       "\n",
       "metric                 auroc            auprc             ausc  \\\n",
       "latent_size                                                      \n",
       "16           0.6097 ± 0.0231   0.7508 ± 0.018     0.77 ± 0.005   \n",
       "32           0.6337 ± 0.0129  0.7661 ± 0.0088  0.7709 ± 0.0019   \n",
       "64           0.5568 ± 0.0145    0.712 ± 0.009  0.7647 ± 0.0026   \n",
       "\n",
       "metric                   ece precision_at_1_expected  \\\n",
       "latent_size                                            \n",
       "16            0.128 ± 0.0059         0.6297 ± 0.0294   \n",
       "32           0.2027 ± 0.0095         0.6374 ± 0.0063   \n",
       "64           0.2152 ± 0.0086          0.522 ± 0.0299   \n",
       "\n",
       "metric      mean_average_precision_expected recall_at_k_expected  \n",
       "latent_size                                                       \n",
       "16                          0.6534 ± 0.0126      0.7013 ± 0.0107  \n",
       "32                           0.649 ± 0.0075      0.6824 ± 0.0112  \n",
       "64                            0.55 ± 0.0209      0.6124 ± 0.0222  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../outputs/PostHoc/figures/CIFAR10/full/metrics.csv\",\n",
    "                 header=None,\n",
    "                 names=[\"metric\", \"value\", \"latent_size\"],\n",
    "                 dtype={\"metric\": str, \"value\": float, \"latent_size\": int})\n",
    "\n",
    "df\\\n",
    "    .sort_values(by=[\"latent_size\", \"metric\"])\\\n",
    "    .groupby([\"latent_size\", \"metric\"]).agg([\"mean\", \"std\"])\n",
    "\n",
    "df = df\\\n",
    "    .sort_values(by=[\"latent_size\", \"metric\"])\\\n",
    "    .groupby([\"latent_size\", \"metric\"]).agg([\"mean\", \"std\"])\\\n",
    "\n",
    "df.columns = df.columns.to_flat_index()\n",
    "\n",
    "df = df.assign(val=lambda x: x[(\"value\", \"mean\")].round(4).apply(str) + \" ± \" + x[(\"value\", \"std\")].round(4).apply(str))\\\n",
    "    .drop([(\"value\", \"mean\"), (\"value\", \"std\")], axis=1)\\\n",
    "    .reset_index()\\\n",
    "    .pivot(index=\"latent_size\", columns=\"metric\", values=\"val\")\n",
    "\n",
    "cols = [\"precision_at_1\", \"mean_average_precision\", \"recall_at_k\", \"auroc\", \"auprc\", \"ausc\", \"ece\", \"precision_at_1_expected\", \"mean_average_precision_expected\", \"recall_at_k_expected\"]\n",
    "df[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.7803            2\n",
      "11                   precision_at_1  0.7358            2\n",
      "12                      recall_at_k  0.9003            2\n",
      "13  mean_average_precision_expected  0.6283            2\n",
      "14          precision_at_1_expected  0.3900            2\n",
      "15             recall_at_k_expected  0.9380            2\n",
      "16                              ece  0.0578            2\n",
      "17                             ausc  0.6208            2\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8778           32\n",
      "11                   precision_at_1  0.8510           32\n",
      "12                      recall_at_k  0.9352           32\n",
      "13  mean_average_precision_expected  0.8163           32\n",
      "14          precision_at_1_expected  0.7452           32\n",
      "15             recall_at_k_expected  0.9203           32\n",
      "16                              ece  0.2754           32\n",
      "17                             ausc  0.9472           32\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.7605            2\n",
      "11                   precision_at_1  0.6743            2\n",
      "12                      recall_at_k  0.9294            2\n",
      "13  mean_average_precision_expected  0.5925            2\n",
      "14          precision_at_1_expected  0.3604            2\n",
      "15             recall_at_k_expected  0.9386            2\n",
      "16                              ece  0.0414            2\n",
      "17                             ausc  0.8665            2\n",
      "                            metric   value  latent_size\n",
      "0           mean_average_precision  0.8078            2\n",
      "1                   precision_at_1  0.7571            2\n",
      "2                      recall_at_k  0.9132            2\n",
      "3  mean_average_precision_expected  0.7718            2\n",
      "4          precision_at_1_expected  0.7093            2\n",
      "5             recall_at_k_expected  0.9256            2\n",
      "6                            auroc  0.9872            2\n",
      "7                            auprc  0.9845            2\n",
      "8                              ece  0.0193            2\n",
      "9                             ausc  0.8762            2\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8604           32\n",
      "11                   precision_at_1  0.8269           32\n",
      "12                      recall_at_k  0.9397           32\n",
      "13  mean_average_precision_expected  0.8401           32\n",
      "14          precision_at_1_expected  0.7953           32\n",
      "15             recall_at_k_expected  0.9251           32\n",
      "16                              ece  0.2790           32\n",
      "17                             ausc  0.9236           32\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8636           32\n",
      "11                   precision_at_1  0.8301           32\n",
      "12                      recall_at_k  0.9391           32\n",
      "13  mean_average_precision_expected  0.8163           32\n",
      "14          precision_at_1_expected  0.8118           32\n",
      "15             recall_at_k_expected  0.9282           32\n",
      "16                              ece  0.2828           32\n",
      "17                             ausc  0.9276           32\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8455           32\n",
      "11                   precision_at_1  0.8031           32\n",
      "12                      recall_at_k  0.9323           32\n",
      "13  mean_average_precision_expected  0.8238           32\n",
      "14          precision_at_1_expected  0.7549           32\n",
      "15             recall_at_k_expected  0.9155           32\n",
      "16                              ece  0.2036           32\n",
      "17                             ausc  0.9021           32\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8604           16\n",
      "11                   precision_at_1  0.8259           16\n",
      "12                      recall_at_k  0.9345           16\n",
      "13  mean_average_precision_expected  0.8543           16\n",
      "14          precision_at_1_expected  0.8179           16\n",
      "15             recall_at_k_expected  0.9255           16\n",
      "16                              ece  0.2653           16\n",
      "17                             ausc  0.9267           16\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8583           16\n",
      "11                   precision_at_1  0.8232           16\n",
      "12                      recall_at_k  0.9343           16\n",
      "13  mean_average_precision_expected  0.8463           16\n",
      "14          precision_at_1_expected  0.8105           16\n",
      "15             recall_at_k_expected  0.9251           16\n",
      "16                              ece  0.2758           16\n",
      "17                             ausc  0.9214           16\n",
      "                             metric   value  latent_size\n",
      "16           mean_average_precision  0.8735           32\n",
      "17                   precision_at_1  0.8430           32\n",
      "18                      recall_at_k  0.9384           32\n",
      "19  mean_average_precision_expected  0.8199           32\n",
      "20          precision_at_1_expected  0.7345           32\n",
      "21             recall_at_k_expected  0.9304           32\n",
      "22                              ece  0.2637           32\n",
      "23                             ausc  0.9367           32\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8439           16\n",
      "11                   precision_at_1  0.8032           16\n",
      "12                      recall_at_k  0.9301           16\n",
      "13  mean_average_precision_expected  0.8386           16\n",
      "14          precision_at_1_expected  0.7991           16\n",
      "15             recall_at_k_expected  0.9157           16\n",
      "16                              ece  0.2098           16\n",
      "17                             ausc  0.8984           16\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8486           16\n",
      "11                   precision_at_1  0.8102           16\n",
      "12                      recall_at_k  0.9320           16\n",
      "13  mean_average_precision_expected  0.8169           16\n",
      "14          precision_at_1_expected  0.7808           16\n",
      "15             recall_at_k_expected  0.9273           16\n",
      "16                              ece  0.2839           16\n",
      "17                             ausc  0.9133           16\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8628           32\n",
      "11                   precision_at_1  0.8305           32\n",
      "12                      recall_at_k  0.9338           32\n",
      "13  mean_average_precision_expected  0.8063           32\n",
      "14          precision_at_1_expected  0.8123           32\n",
      "15             recall_at_k_expected  0.9292           32\n",
      "16                              ece  0.2170           32\n",
      "17                             ausc  0.9115           32\n",
      "                            metric   value  latent_size\n",
      "0           mean_average_precision  0.8600           16\n",
      "1                   precision_at_1  0.8284           16\n",
      "2                      recall_at_k  0.9291           16\n",
      "3  mean_average_precision_expected  0.8460           16\n",
      "4          precision_at_1_expected  0.8200           16\n",
      "5             recall_at_k_expected  0.9190           16\n",
      "6                              ece  0.2667           16\n",
      "7                             ausc  0.9206           16\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8678           32\n",
      "11                   precision_at_1  0.8342           32\n",
      "12                      recall_at_k  0.9388           32\n",
      "13  mean_average_precision_expected  0.8289           32\n",
      "14          precision_at_1_expected  0.8122           32\n",
      "15             recall_at_k_expected  0.9281           32\n",
      "16                              ece  0.2754           32\n",
      "17                             ausc  0.9292           32\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8539           16\n",
      "11                   precision_at_1  0.8066           16\n",
      "12                      recall_at_k  0.9370           16\n",
      "13  mean_average_precision_expected  0.8035           16\n",
      "14          precision_at_1_expected  0.7218           16\n",
      "15             recall_at_k_expected  0.9312           16\n",
      "16                              ece  0.2383           16\n",
      "17                             ausc  0.9328           16\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.7872            2\n",
      "11                   precision_at_1  0.7278            2\n",
      "12                      recall_at_k  0.9116            2\n",
      "13  mean_average_precision_expected  0.6769            2\n",
      "14          precision_at_1_expected  0.5073            2\n",
      "15             recall_at_k_expected  0.9560            2\n",
      "16                              ece  0.0447            2\n",
      "17                             ausc  0.8365            2\n",
      "                            metric   value  latent_size\n",
      "0           mean_average_precision  0.8070            2\n",
      "1                   precision_at_1  0.7553            2\n",
      "2                      recall_at_k  0.9164            2\n",
      "3  mean_average_precision_expected  0.7422            2\n",
      "4          precision_at_1_expected  0.6345            2\n",
      "5             recall_at_k_expected  0.9039            2\n",
      "6                            auroc  0.9873            2\n",
      "7                            auprc  0.9846            2\n",
      "8                              ece  0.0312            2\n",
      "9                             ausc  0.8924            2\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8626           32\n",
      "11                   precision_at_1  0.8284           32\n",
      "12                      recall_at_k  0.9318           32\n",
      "13  mean_average_precision_expected  0.7567           32\n",
      "14          precision_at_1_expected  0.7370           32\n",
      "15             recall_at_k_expected  0.9112           32\n",
      "16                              ece  0.2579           32\n",
      "17                             ausc  0.9326           32\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8409           16\n",
      "11                   precision_at_1  0.7848           16\n",
      "12                      recall_at_k  0.9360           16\n",
      "13  mean_average_precision_expected  0.8316           16\n",
      "14          precision_at_1_expected  0.7614           16\n",
      "15             recall_at_k_expected  0.9168           16\n",
      "16                              ece  0.2089           16\n",
      "17                             ausc  0.9272           16\n",
      "                            metric   value  latent_size\n",
      "0           mean_average_precision  0.8056            2\n",
      "1                   precision_at_1  0.7548            2\n",
      "2                      recall_at_k  0.9157            2\n",
      "3  mean_average_precision_expected  0.8025            2\n",
      "4          precision_at_1_expected  0.7555            2\n",
      "5             recall_at_k_expected  0.9115            2\n",
      "6                            auroc  0.9873            2\n",
      "7                            auprc  0.9823            2\n",
      "8                              ece  0.0298            2\n",
      "9                             ausc  0.8804            2\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8679           32\n",
      "11                   precision_at_1  0.8339           32\n",
      "12                      recall_at_k  0.9413           32\n",
      "13  mean_average_precision_expected  0.8132           32\n",
      "14          precision_at_1_expected  0.7526           32\n",
      "15             recall_at_k_expected  0.9329           32\n",
      "16                              ece  0.2825           32\n",
      "17                             ausc  0.9261           32\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8441           32\n",
      "11                   precision_at_1  0.7656           32\n",
      "12                      recall_at_k  0.9356           32\n",
      "13  mean_average_precision_expected  0.7928           32\n",
      "14          precision_at_1_expected  0.7123           32\n",
      "15             recall_at_k_expected  0.9212           32\n",
      "16                              ece  0.2723           32\n",
      "17                             ausc  0.9275           32\n",
      "                            metric   value  latent_size\n",
      "0           mean_average_precision  0.8103            2\n",
      "1                   precision_at_1  0.7633            2\n",
      "2                      recall_at_k  0.9167            2\n",
      "3  mean_average_precision_expected  0.7617            2\n",
      "4          precision_at_1_expected  0.6677            2\n",
      "5             recall_at_k_expected  0.9113            2\n",
      "6                            auroc  0.9878            2\n",
      "7                            auprc  0.9847            2\n",
      "8                              ece  0.0167            2\n",
      "9                             ausc  0.8724            2\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8475           16\n",
      "11                   precision_at_1  0.8093           16\n",
      "12                      recall_at_k  0.9306           16\n",
      "13  mean_average_precision_expected  0.8394           16\n",
      "14          precision_at_1_expected  0.8200           16\n",
      "15             recall_at_k_expected  0.9198           16\n",
      "16                              ece  0.2368           16\n",
      "17                             ausc  0.9190           16\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8607           16\n",
      "11                   precision_at_1  0.8306           16\n",
      "12                      recall_at_k  0.9355           16\n",
      "13  mean_average_precision_expected  0.8479           16\n",
      "14          precision_at_1_expected  0.8173           16\n",
      "15             recall_at_k_expected  0.9134           16\n",
      "16                              ece  0.2746           16\n",
      "17                             ausc  0.9357           16\n",
      "                            metric   value  latent_size\n",
      "0           mean_average_precision  0.8076            2\n",
      "1                   precision_at_1  0.7581            2\n",
      "2                      recall_at_k  0.9157            2\n",
      "3  mean_average_precision_expected  0.6991            2\n",
      "4          precision_at_1_expected  0.5676            2\n",
      "5             recall_at_k_expected  0.8987            2\n",
      "6                            auroc  0.9801            2\n",
      "7                            auprc  0.9757            2\n",
      "8                              ece  0.0201            2\n",
      "9                             ausc  0.8905            2\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8585           16\n",
      "11                   precision_at_1  0.8242           16\n",
      "12                      recall_at_k  0.9343           16\n",
      "13  mean_average_precision_expected  0.8509           16\n",
      "14          precision_at_1_expected  0.8226           16\n",
      "15             recall_at_k_expected  0.9176           16\n",
      "16                              ece  0.2840           16\n",
      "17                             ausc  0.9261           16\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8709           32\n",
      "11                   precision_at_1  0.8479           32\n",
      "12                      recall_at_k  0.9380           32\n",
      "13  mean_average_precision_expected  0.8451           32\n",
      "14          precision_at_1_expected  0.8298           32\n",
      "15             recall_at_k_expected  0.9313           32\n",
      "16                              ece  0.2603           32\n",
      "17                             ausc  0.9396           32\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8678           32\n",
      "11                   precision_at_1  0.8384           32\n",
      "12                      recall_at_k  0.9358           32\n",
      "13  mean_average_precision_expected  0.7997           32\n",
      "14          precision_at_1_expected  0.7771           32\n",
      "15             recall_at_k_expected  0.9078           32\n",
      "16                              ece  0.2548           32\n",
      "17                             ausc  0.9229           32\n",
      "                            metric   value  latent_size\n",
      "0           mean_average_precision  0.8628           32\n",
      "1                   precision_at_1  0.8307           32\n",
      "2                      recall_at_k  0.9331           32\n",
      "3  mean_average_precision_expected  0.7851           32\n",
      "4          precision_at_1_expected  0.6848           32\n",
      "5             recall_at_k_expected  0.9100           32\n",
      "6                              ece  0.2286           32\n",
      "7                             ausc  0.9144           32\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8006            2\n",
      "11                   precision_at_1  0.7503            2\n",
      "12                      recall_at_k  0.9235            2\n",
      "13  mean_average_precision_expected  0.7083            2\n",
      "14          precision_at_1_expected  0.5675            2\n",
      "15             recall_at_k_expected  0.9447            2\n",
      "16                              ece  0.0661            2\n",
      "17                             ausc  0.8746            2\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8439           16\n",
      "11                   precision_at_1  0.7696           16\n",
      "12                      recall_at_k  0.9361           16\n",
      "13  mean_average_precision_expected  0.8056           16\n",
      "14          precision_at_1_expected  0.7208           16\n",
      "15             recall_at_k_expected  0.9138           16\n",
      "16                              ece  0.2518           16\n",
      "17                             ausc  0.9263           16\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8433           16\n",
      "11                   precision_at_1  0.8051           16\n",
      "12                      recall_at_k  0.9316           16\n",
      "13  mean_average_precision_expected  0.8371           16\n",
      "14          precision_at_1_expected  0.7919           16\n",
      "15             recall_at_k_expected  0.9194           16\n",
      "16                              ece  0.2396           16\n",
      "17                             ausc  0.8848           16\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.7720            2\n",
      "11                   precision_at_1  0.7123            2\n",
      "12                      recall_at_k  0.9155            2\n",
      "13  mean_average_precision_expected  0.6109            2\n",
      "14          precision_at_1_expected  0.4192            2\n",
      "15             recall_at_k_expected  0.8664            2\n",
      "16                              ece  0.0153            2\n",
      "17                             ausc  0.8841            2\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.7680            2\n",
      "11                   precision_at_1  0.6985            2\n",
      "12                      recall_at_k  0.9154            2\n",
      "13  mean_average_precision_expected  0.6184            2\n",
      "14          precision_at_1_expected  0.3510            2\n",
      "15             recall_at_k_expected  0.9459            2\n",
      "16                              ece  0.0225            2\n",
      "17                             ausc  0.8592            2\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8620           32\n",
      "11                   precision_at_1  0.8363           32\n",
      "12                      recall_at_k  0.9400           32\n",
      "13  mean_average_precision_expected  0.8406           32\n",
      "14          precision_at_1_expected  0.8109           32\n",
      "15             recall_at_k_expected  0.9136           32\n",
      "16                              ece  0.2604           32\n",
      "17                             ausc  0.9409           32\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.7814            2\n",
      "11                   precision_at_1  0.7110            2\n",
      "12                      recall_at_k  0.9244            2\n",
      "13  mean_average_precision_expected  0.7114            2\n",
      "14          precision_at_1_expected  0.5413            2\n",
      "15             recall_at_k_expected  0.9410            2\n",
      "16                              ece  0.0692            2\n",
      "17                             ausc  0.8779            2\n",
      "                            metric   value  latent_size\n",
      "0           mean_average_precision  0.8074            2\n",
      "1                   precision_at_1  0.7562            2\n",
      "2                      recall_at_k  0.9171            2\n",
      "3  mean_average_precision_expected  0.7596            2\n",
      "4          precision_at_1_expected  0.6314            2\n",
      "5             recall_at_k_expected  0.9360            2\n",
      "6                            auroc  0.9837            2\n",
      "7                            auprc  0.9787            2\n",
      "8                              ece  0.0186            2\n",
      "9                             ausc  0.8752            2\n",
      "                            metric   value  latent_size\n",
      "0           mean_average_precision  0.7879            2\n",
      "1                   precision_at_1  0.7304            2\n",
      "2                      recall_at_k  0.9087            2\n",
      "3  mean_average_precision_expected  0.7864            2\n",
      "4          precision_at_1_expected  0.6762            2\n",
      "5             recall_at_k_expected  0.9254            2\n",
      "6                            auroc  0.9771            2\n",
      "7                            auprc  0.9730            2\n",
      "8                              ece  0.0152            2\n",
      "9                             ausc  0.8669            2\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8689           16\n",
      "11                   precision_at_1  0.8379           16\n",
      "12                      recall_at_k  0.9385           16\n",
      "13  mean_average_precision_expected  0.8108           16\n",
      "14          precision_at_1_expected  0.8153           16\n",
      "15             recall_at_k_expected  0.9238           16\n",
      "16                              ece  0.3025           16\n",
      "17                             ausc  0.9341           16\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8641           32\n",
      "11                   precision_at_1  0.8284           32\n",
      "12                      recall_at_k  0.9368           32\n",
      "13  mean_average_precision_expected  0.8117           32\n",
      "14          precision_at_1_expected  0.8137           32\n",
      "15             recall_at_k_expected  0.9194           32\n",
      "16                              ece  0.2343           32\n",
      "17                             ausc  0.9339           32\n",
      "                             metric   value  latent_size\n",
      "20           mean_average_precision  0.7901            2\n",
      "21                   precision_at_1  0.7273            2\n",
      "22                      recall_at_k  0.9177            2\n",
      "23  mean_average_precision_expected  0.6810            2\n",
      "24          precision_at_1_expected  0.4790            2\n",
      "25             recall_at_k_expected  0.9318            2\n",
      "26                              ece  0.0463            2\n",
      "27                             ausc  0.8379            2\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8676           16\n",
      "11                   precision_at_1  0.8353           16\n",
      "12                      recall_at_k  0.9376           16\n",
      "13  mean_average_precision_expected  0.8598           16\n",
      "14          precision_at_1_expected  0.8312           16\n",
      "15             recall_at_k_expected  0.9216           16\n",
      "16                              ece  0.2966           16\n",
      "17                             ausc  0.9344           16\n",
      "                             metric   value  latent_size\n",
      "10           mean_average_precision  0.8538           16\n",
      "11                   precision_at_1  0.8193           16\n",
      "12                      recall_at_k  0.9349           16\n",
      "13  mean_average_precision_expected  0.8443           16\n",
      "14          precision_at_1_expected  0.8096           16\n",
      "15             recall_at_k_expected  0.9263           16\n",
      "16                              ece  0.2389           16\n",
      "17                             ausc  0.9048           16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>precision_at_1</th>\n",
       "      <th>mean_average_precision</th>\n",
       "      <th>recall_at_k</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>ausc</th>\n",
       "      <th>ece</th>\n",
       "      <th>precision_at_1_expected</th>\n",
       "      <th>mean_average_precision_expected</th>\n",
       "      <th>recall_at_k_expected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latent_size</th>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>A: fixed</th>\n",
       "      <td>0.7343 ± 0.0182</td>\n",
       "      <td>0.7933 ± 0.0104</td>\n",
       "      <td>0.9187 ± 0.0053</td>\n",
       "      <td>0.9857 ± 0.0067</td>\n",
       "      <td>0.9837 ± 0.0065</td>\n",
       "      <td>0.8639 ± 0.0252</td>\n",
       "      <td>0.0515 ± 0.0159</td>\n",
       "      <td>0.5459 ± 0.0598</td>\n",
       "      <td>0.7039 ± 0.0264</td>\n",
       "      <td>0.9355 ± 0.0197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B: positives</th>\n",
       "      <td>0.7526 ± 0.0128</td>\n",
       "      <td>0.8038 ± 0.009</td>\n",
       "      <td>0.9148 ± 0.0035</td>\n",
       "      <td>0.9832 ± 0.0044</td>\n",
       "      <td>0.9789 ± 0.0045</td>\n",
       "      <td>0.8771 ± 0.009</td>\n",
       "      <td>0.0201 ± 0.0058</td>\n",
       "      <td>0.6597 ± 0.0686</td>\n",
       "      <td>0.7619 ± 0.0394</td>\n",
       "      <td>0.9166 ± 0.0144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C: full</th>\n",
       "      <td>0.7156 ± 0.0322</td>\n",
       "      <td>0.7777 ± 0.0182</td>\n",
       "      <td>0.9148 ± 0.0103</td>\n",
       "      <td>0.9358 ± 0.0731</td>\n",
       "      <td>0.9442 ± 0.0557</td>\n",
       "      <td>0.8213 ± 0.1125</td>\n",
       "      <td>0.0312 ± 0.0179</td>\n",
       "      <td>0.446 ± 0.1496</td>\n",
       "      <td>0.6444 ± 0.0724</td>\n",
       "      <td>0.9229 ± 0.0324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">16</th>\n",
       "      <th>A: fixed</th>\n",
       "      <td>0.8145 ± 0.0182</td>\n",
       "      <td>0.8534 ± 0.0088</td>\n",
       "      <td>0.9329 ± 0.0029</td>\n",
       "      <td>0.9385 ± 0.0649</td>\n",
       "      <td>0.9506 ± 0.0507</td>\n",
       "      <td>0.9239 ± 0.0038</td>\n",
       "      <td>0.2523 ± 0.0296</td>\n",
       "      <td>0.8084 ± 0.0263</td>\n",
       "      <td>0.8444 ± 0.0091</td>\n",
       "      <td>0.9197 ± 0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B: positives</th>\n",
       "      <td>0.8238 ± 0.0151</td>\n",
       "      <td>0.8578 ± 0.0114</td>\n",
       "      <td>0.935 ± 0.0032</td>\n",
       "      <td>0.7813 ± 0.2123</td>\n",
       "      <td>0.8044 ± 0.2025</td>\n",
       "      <td>0.9205 ± 0.022</td>\n",
       "      <td>0.2794 ± 0.0248</td>\n",
       "      <td>0.8073 ± 0.0205</td>\n",
       "      <td>0.8345 ± 0.0206</td>\n",
       "      <td>0.9211 ± 0.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C: full</th>\n",
       "      <td>0.8044 ± 0.0212</td>\n",
       "      <td>0.8508 ± 0.0065</td>\n",
       "      <td>0.9345 ± 0.0027</td>\n",
       "      <td>0.8689 ± 0.1306</td>\n",
       "      <td>0.8918 ± 0.0974</td>\n",
       "      <td>0.9167 ± 0.0146</td>\n",
       "      <td>0.2429 ± 0.0239</td>\n",
       "      <td>0.7724 ± 0.0468</td>\n",
       "      <td>0.8276 ± 0.0213</td>\n",
       "      <td>0.9224 ± 0.0074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">32</th>\n",
       "      <th>A: fixed</th>\n",
       "      <td>0.8279 ± 0.0149</td>\n",
       "      <td>0.8624 ± 0.0104</td>\n",
       "      <td>0.9349 ± 0.0034</td>\n",
       "      <td>0.9351 ± 0.0343</td>\n",
       "      <td>0.9452 ± 0.0243</td>\n",
       "      <td>0.923 ± 0.0144</td>\n",
       "      <td>0.2458 ± 0.0292</td>\n",
       "      <td>0.7447 ± 0.0459</td>\n",
       "      <td>0.8029 ± 0.031</td>\n",
       "      <td>0.919 ± 0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B: positives</th>\n",
       "      <td>0.8222 ± 0.0328</td>\n",
       "      <td>0.8632 ± 0.0123</td>\n",
       "      <td>0.937 ± 0.0031</td>\n",
       "      <td>0.8456 ± 0.165</td>\n",
       "      <td>0.8538 ± 0.1674</td>\n",
       "      <td>0.928 ± 0.0127</td>\n",
       "      <td>0.266 ± 0.0277</td>\n",
       "      <td>0.7668 ± 0.044</td>\n",
       "      <td>0.809 ± 0.0099</td>\n",
       "      <td>0.9264 ± 0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C: full</th>\n",
       "      <td>0.8356 ± 0.0085</td>\n",
       "      <td>0.865 ± 0.0043</td>\n",
       "      <td>0.9381 ± 0.0018</td>\n",
       "      <td>0.8856 ± 0.0501</td>\n",
       "      <td>0.9009 ± 0.0397</td>\n",
       "      <td>0.9322 ± 0.0085</td>\n",
       "      <td>0.2578 ± 0.016</td>\n",
       "      <td>0.8054 ± 0.02</td>\n",
       "      <td>0.8274 ± 0.0204</td>\n",
       "      <td>0.9194 ± 0.0093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                     precision_at_1 mean_average_precision  \\\n",
       "latent_size method                                                 \n",
       "2           A: fixed      0.7343 ± 0.0182        0.7933 ± 0.0104   \n",
       "            B: positives  0.7526 ± 0.0128         0.8038 ± 0.009   \n",
       "            C: full       0.7156 ± 0.0322        0.7777 ± 0.0182   \n",
       "16          A: fixed      0.8145 ± 0.0182        0.8534 ± 0.0088   \n",
       "            B: positives  0.8238 ± 0.0151        0.8578 ± 0.0114   \n",
       "            C: full       0.8044 ± 0.0212        0.8508 ± 0.0065   \n",
       "32          A: fixed      0.8279 ± 0.0149        0.8624 ± 0.0104   \n",
       "            B: positives  0.8222 ± 0.0328        0.8632 ± 0.0123   \n",
       "            C: full       0.8356 ± 0.0085         0.865 ± 0.0043   \n",
       "\n",
       "metric                        recall_at_k            auroc            auprc  \\\n",
       "latent_size method                                                            \n",
       "2           A: fixed      0.9187 ± 0.0053  0.9857 ± 0.0067  0.9837 ± 0.0065   \n",
       "            B: positives  0.9148 ± 0.0035  0.9832 ± 0.0044  0.9789 ± 0.0045   \n",
       "            C: full       0.9148 ± 0.0103  0.9358 ± 0.0731  0.9442 ± 0.0557   \n",
       "16          A: fixed      0.9329 ± 0.0029  0.9385 ± 0.0649  0.9506 ± 0.0507   \n",
       "            B: positives   0.935 ± 0.0032  0.7813 ± 0.2123  0.8044 ± 0.2025   \n",
       "            C: full       0.9345 ± 0.0027  0.8689 ± 0.1306  0.8918 ± 0.0974   \n",
       "32          A: fixed      0.9349 ± 0.0034  0.9351 ± 0.0343  0.9452 ± 0.0243   \n",
       "            B: positives   0.937 ± 0.0031   0.8456 ± 0.165  0.8538 ± 0.1674   \n",
       "            C: full       0.9381 ± 0.0018  0.8856 ± 0.0501  0.9009 ± 0.0397   \n",
       "\n",
       "metric                               ausc              ece  \\\n",
       "latent_size method                                           \n",
       "2           A: fixed      0.8639 ± 0.0252  0.0515 ± 0.0159   \n",
       "            B: positives   0.8771 ± 0.009  0.0201 ± 0.0058   \n",
       "            C: full       0.8213 ± 0.1125  0.0312 ± 0.0179   \n",
       "16          A: fixed      0.9239 ± 0.0038  0.2523 ± 0.0296   \n",
       "            B: positives   0.9205 ± 0.022  0.2794 ± 0.0248   \n",
       "            C: full       0.9167 ± 0.0146  0.2429 ± 0.0239   \n",
       "32          A: fixed       0.923 ± 0.0144  0.2458 ± 0.0292   \n",
       "            B: positives   0.928 ± 0.0127   0.266 ± 0.0277   \n",
       "            C: full       0.9322 ± 0.0085   0.2578 ± 0.016   \n",
       "\n",
       "metric                   precision_at_1_expected  \\\n",
       "latent_size method                                 \n",
       "2           A: fixed             0.5459 ± 0.0598   \n",
       "            B: positives         0.6597 ± 0.0686   \n",
       "            C: full               0.446 ± 0.1496   \n",
       "16          A: fixed             0.8084 ± 0.0263   \n",
       "            B: positives         0.8073 ± 0.0205   \n",
       "            C: full              0.7724 ± 0.0468   \n",
       "32          A: fixed             0.7447 ± 0.0459   \n",
       "            B: positives          0.7668 ± 0.044   \n",
       "            C: full                0.8054 ± 0.02   \n",
       "\n",
       "metric                   mean_average_precision_expected recall_at_k_expected  \n",
       "latent_size method                                                             \n",
       "2           A: fixed                     0.7039 ± 0.0264      0.9355 ± 0.0197  \n",
       "            B: positives                 0.7619 ± 0.0394      0.9166 ± 0.0144  \n",
       "            C: full                      0.6444 ± 0.0724      0.9229 ± 0.0324  \n",
       "16          A: fixed                     0.8444 ± 0.0091      0.9197 ± 0.0034  \n",
       "            B: positives                 0.8345 ± 0.0206      0.9211 ± 0.0052  \n",
       "            C: full                      0.8276 ± 0.0213      0.9224 ± 0.0074  \n",
       "32          A: fixed                      0.8029 ± 0.031       0.919 ± 0.0096  \n",
       "            B: positives                  0.809 ± 0.0099      0.9264 ± 0.0054  \n",
       "            C: full                      0.8274 ± 0.0204      0.9194 ± 0.0093  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "dfs = []\n",
    "for folder in Path(\"../outputs/Online/figures/FashionMNIST\").glob(\"*\"):\n",
    "    method, latent_size, _, seed = folder.name.split(\"_\")\n",
    "\n",
    "    df = pd.read_csv(folder / \"metrics.csv\",\n",
    "                     header=None,\n",
    "                     names=[\"metric\", \"value\", \"latent_size\"],\n",
    "                     dtype={\"metric\": str, \"value\": float, \"latent_size\": int})\n",
    "    if len(df) > 12:\n",
    "        df = df[-8:]\n",
    "    print(df)\n",
    "    ood_metrics = json.load(open(folder / \"ood_metrics.json\"))\n",
    "    ood_metrics = pd.DataFrame({\"metric\": [\"auroc\", \"auprc\"], \"value\": [ood_metrics[\"auroc\"], ood_metrics[\"auprc\"]]})\n",
    "    df = pd.concat([df, ood_metrics], axis=0)\n",
    "    df[\"seed\"] = int(seed)\n",
    "    df[\"latent_size\"] = int(latent_size)\n",
    "    df[\"method\"] = method\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df[\"method\"] = df[\"method\"].str.replace(\"fixed\", \"A: fixed\")\n",
    "df[\"method\"] = df[\"method\"].str.replace(\"positives\", \"B: positives\")\n",
    "df[\"method\"] = df[\"method\"].str.replace(\"full\", \"C: full\")\n",
    "\n",
    "df = df\\\n",
    "    .sort_values(by=[\"latent_size\", \"metric\"])\\\n",
    "    .groupby([\"method\", \"latent_size\", \"metric\"]).agg([\"mean\", \"std\"])\\\n",
    "\n",
    "df.columns = df.columns.to_flat_index()\n",
    "\n",
    "df = df.assign(val=lambda x: x[(\"value\", \"mean\")].round(4).apply(str) + \" ± \" + x[(\"value\", \"std\")].round(4).apply(str))\\\n",
    "    .drop([(\"value\", \"mean\"), (\"value\", \"std\")], axis=1)\\\n",
    "    .reset_index()\\\n",
    "    .pivot(index=[\"latent_size\", \"method\"], columns=\"metric\", values=\"val\")\n",
    "\n",
    "cols = [\"precision_at_1\", \"mean_average_precision\", \"recall_at_k\", \"auroc\", \"auprc\", \"ausc\", \"ece\", \"precision_at_1_expected\", \"mean_average_precision_expected\", \"recall_at_k_expected\"]\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>precision_at_1</th>\n",
       "      <th>mean_average_precision</th>\n",
       "      <th>recall_at_k</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>ausc</th>\n",
       "      <th>ece</th>\n",
       "      <th>precision_at_1_expected</th>\n",
       "      <th>mean_average_precision_expected</th>\n",
       "      <th>recall_at_k_expected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latent_size</th>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">16</th>\n",
       "      <th>A: fixed</th>\n",
       "      <td>0.5695 ± 0.0064</td>\n",
       "      <td>0.6387 ± 0.0052</td>\n",
       "      <td>0.786 ± 0.0034</td>\n",
       "      <td>0.4811 ± 0.0209</td>\n",
       "      <td>0.6688 ± 0.0117</td>\n",
       "      <td>0.7207 ± 0.0089</td>\n",
       "      <td>0.0347 ± 0.0024</td>\n",
       "      <td>0.5304 ± 0.0112</td>\n",
       "      <td>0.5544 ± 0.0088</td>\n",
       "      <td>0.623 ± 0.0293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B: positives</th>\n",
       "      <td>0.5661 ± 0.0076</td>\n",
       "      <td>0.6371 ± 0.0073</td>\n",
       "      <td>0.7882 ± 0.005</td>\n",
       "      <td>0.4604 ± 0.0328</td>\n",
       "      <td>0.6586 ± 0.0169</td>\n",
       "      <td>0.7167 ± 0.013</td>\n",
       "      <td>0.0312 ± 0.0036</td>\n",
       "      <td>0.5238 ± 0.022</td>\n",
       "      <td>0.5481 ± 0.0166</td>\n",
       "      <td>0.6036 ± 0.0169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C: full</th>\n",
       "      <td>0.5579 ± 0.0044</td>\n",
       "      <td>0.6304 ± 0.004</td>\n",
       "      <td>0.7825 ± 0.0036</td>\n",
       "      <td>0.4434 ± 0.0255</td>\n",
       "      <td>0.6477 ± 0.012</td>\n",
       "      <td>0.7073 ± 0.0093</td>\n",
       "      <td>0.0329 ± 0.001</td>\n",
       "      <td>0.508 ± 0.0069</td>\n",
       "      <td>0.538 ± 0.0219</td>\n",
       "      <td>0.6102 ± 0.0393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">32</th>\n",
       "      <th>A: fixed</th>\n",
       "      <td>0.5713 ± 0.0035</td>\n",
       "      <td>0.6401 ± 0.004</td>\n",
       "      <td>0.7888 ± 0.0027</td>\n",
       "      <td>0.457 ± 0.0314</td>\n",
       "      <td>0.6525 ± 0.0154</td>\n",
       "      <td>0.7248 ± 0.0063</td>\n",
       "      <td>0.0595 ± 0.0025</td>\n",
       "      <td>0.4426 ± 0.0226</td>\n",
       "      <td>0.4925 ± 0.0138</td>\n",
       "      <td>0.6084 ± 0.0326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B: positives</th>\n",
       "      <td>0.5711 ± 0.0099</td>\n",
       "      <td>0.6429 ± 0.0061</td>\n",
       "      <td>0.7913 ± 0.005</td>\n",
       "      <td>0.451 ± 0.033</td>\n",
       "      <td>0.6462 ± 0.0176</td>\n",
       "      <td>0.7244 ± 0.0056</td>\n",
       "      <td>0.0556 ± 0.0042</td>\n",
       "      <td>0.4454 ± 0.0677</td>\n",
       "      <td>0.491 ± 0.0264</td>\n",
       "      <td>0.5876 ± 0.0453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C: full</th>\n",
       "      <td>0.572 ± 0.0069</td>\n",
       "      <td>0.6417 ± 0.0055</td>\n",
       "      <td>0.7901 ± 0.0064</td>\n",
       "      <td>0.4251 ± 0.0225</td>\n",
       "      <td>0.6336 ± 0.0107</td>\n",
       "      <td>0.7161 ± 0.0108</td>\n",
       "      <td>0.0568 ± 0.0062</td>\n",
       "      <td>0.4307 ± 0.0505</td>\n",
       "      <td>0.4724 ± 0.035</td>\n",
       "      <td>0.5534 ± 0.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">64</th>\n",
       "      <th>A: fixed</th>\n",
       "      <td>0.5734 ± 0.0043</td>\n",
       "      <td>0.6407 ± 0.0027</td>\n",
       "      <td>0.7886 ± 0.0041</td>\n",
       "      <td>0.4554 ± 0.0292</td>\n",
       "      <td>0.646 ± 0.0138</td>\n",
       "      <td>0.7154 ± 0.006</td>\n",
       "      <td>0.075 ± 0.0084</td>\n",
       "      <td>0.4186 ± 0.0583</td>\n",
       "      <td>0.4584 ± 0.0522</td>\n",
       "      <td>0.5232 ± 0.0521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B: positives</th>\n",
       "      <td>0.5665 ± 0.0072</td>\n",
       "      <td>0.6391 ± 0.0041</td>\n",
       "      <td>0.7889 ± 0.0048</td>\n",
       "      <td>0.45 ± 0.0226</td>\n",
       "      <td>0.6431 ± 0.0087</td>\n",
       "      <td>0.7172 ± 0.0086</td>\n",
       "      <td>0.0791 ± 0.0089</td>\n",
       "      <td>0.4006 ± 0.0382</td>\n",
       "      <td>0.4253 ± 0.0395</td>\n",
       "      <td>0.5124 ± 0.0648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C: full</th>\n",
       "      <td>0.5694 ± 0.0049</td>\n",
       "      <td>0.639 ± 0.0029</td>\n",
       "      <td>0.7869 ± 0.0038</td>\n",
       "      <td>0.4392 ± 0.0135</td>\n",
       "      <td>0.6377 ± 0.0064</td>\n",
       "      <td>0.7136 ± 0.0059</td>\n",
       "      <td>0.0756 ± 0.0079</td>\n",
       "      <td>0.3663 ± 0.0272</td>\n",
       "      <td>0.425 ± 0.0534</td>\n",
       "      <td>0.508 ± 0.0956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                     precision_at_1 mean_average_precision  \\\n",
       "latent_size method                                                 \n",
       "16          A: fixed      0.5695 ± 0.0064        0.6387 ± 0.0052   \n",
       "            B: positives  0.5661 ± 0.0076        0.6371 ± 0.0073   \n",
       "            C: full       0.5579 ± 0.0044         0.6304 ± 0.004   \n",
       "32          A: fixed      0.5713 ± 0.0035         0.6401 ± 0.004   \n",
       "            B: positives  0.5711 ± 0.0099        0.6429 ± 0.0061   \n",
       "            C: full        0.572 ± 0.0069        0.6417 ± 0.0055   \n",
       "64          A: fixed      0.5734 ± 0.0043        0.6407 ± 0.0027   \n",
       "            B: positives  0.5665 ± 0.0072        0.6391 ± 0.0041   \n",
       "            C: full       0.5694 ± 0.0049         0.639 ± 0.0029   \n",
       "\n",
       "metric                        recall_at_k            auroc            auprc  \\\n",
       "latent_size method                                                            \n",
       "16          A: fixed       0.786 ± 0.0034  0.4811 ± 0.0209  0.6688 ± 0.0117   \n",
       "            B: positives   0.7882 ± 0.005  0.4604 ± 0.0328  0.6586 ± 0.0169   \n",
       "            C: full       0.7825 ± 0.0036  0.4434 ± 0.0255   0.6477 ± 0.012   \n",
       "32          A: fixed      0.7888 ± 0.0027   0.457 ± 0.0314  0.6525 ± 0.0154   \n",
       "            B: positives   0.7913 ± 0.005    0.451 ± 0.033  0.6462 ± 0.0176   \n",
       "            C: full       0.7901 ± 0.0064  0.4251 ± 0.0225  0.6336 ± 0.0107   \n",
       "64          A: fixed      0.7886 ± 0.0041  0.4554 ± 0.0292   0.646 ± 0.0138   \n",
       "            B: positives  0.7889 ± 0.0048    0.45 ± 0.0226  0.6431 ± 0.0087   \n",
       "            C: full       0.7869 ± 0.0038  0.4392 ± 0.0135  0.6377 ± 0.0064   \n",
       "\n",
       "metric                               ausc              ece  \\\n",
       "latent_size method                                           \n",
       "16          A: fixed      0.7207 ± 0.0089  0.0347 ± 0.0024   \n",
       "            B: positives   0.7167 ± 0.013  0.0312 ± 0.0036   \n",
       "            C: full       0.7073 ± 0.0093   0.0329 ± 0.001   \n",
       "32          A: fixed      0.7248 ± 0.0063  0.0595 ± 0.0025   \n",
       "            B: positives  0.7244 ± 0.0056  0.0556 ± 0.0042   \n",
       "            C: full       0.7161 ± 0.0108  0.0568 ± 0.0062   \n",
       "64          A: fixed       0.7154 ± 0.006   0.075 ± 0.0084   \n",
       "            B: positives  0.7172 ± 0.0086  0.0791 ± 0.0089   \n",
       "            C: full       0.7136 ± 0.0059  0.0756 ± 0.0079   \n",
       "\n",
       "metric                   precision_at_1_expected  \\\n",
       "latent_size method                                 \n",
       "16          A: fixed             0.5304 ± 0.0112   \n",
       "            B: positives          0.5238 ± 0.022   \n",
       "            C: full               0.508 ± 0.0069   \n",
       "32          A: fixed             0.4426 ± 0.0226   \n",
       "            B: positives         0.4454 ± 0.0677   \n",
       "            C: full              0.4307 ± 0.0505   \n",
       "64          A: fixed             0.4186 ± 0.0583   \n",
       "            B: positives         0.4006 ± 0.0382   \n",
       "            C: full              0.3663 ± 0.0272   \n",
       "\n",
       "metric                   mean_average_precision_expected recall_at_k_expected  \n",
       "latent_size method                                                             \n",
       "16          A: fixed                     0.5544 ± 0.0088       0.623 ± 0.0293  \n",
       "            B: positives                 0.5481 ± 0.0166      0.6036 ± 0.0169  \n",
       "            C: full                       0.538 ± 0.0219      0.6102 ± 0.0393  \n",
       "32          A: fixed                     0.4925 ± 0.0138      0.6084 ± 0.0326  \n",
       "            B: positives                  0.491 ± 0.0264      0.5876 ± 0.0453  \n",
       "            C: full                       0.4724 ± 0.035      0.5534 ± 0.0552  \n",
       "64          A: fixed                     0.4584 ± 0.0522      0.5232 ± 0.0521  \n",
       "            B: positives                 0.4253 ± 0.0395      0.5124 ± 0.0648  \n",
       "            C: full                       0.425 ± 0.0534       0.508 ± 0.0956  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dfs = []\n",
    "for folder in Path(\"../outputs/Online/figures/CIFAR10\").glob(\"*\"):\n",
    "    try:\n",
    "        method, latent_size, _, seed = folder.name.split(\"_\")\n",
    "\n",
    "        df = pd.read_csv(folder / \"metrics.csv\",\n",
    "                        header=None,\n",
    "                        names=[\"metric\", \"value\", \"latent_size\"],\n",
    "                        dtype={\"metric\": str, \"value\": float, \"latent_size\": int})\n",
    "        df[\"seed\"] = int(seed)\n",
    "        df[\"latent_size\"] = int(latent_size)\n",
    "        df[\"method\"] = method\n",
    "        dfs.append(df)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df[\"method\"] = df[\"method\"].str.replace(\"fixed\", \"A: fixed\")\n",
    "df[\"method\"] = df[\"method\"].str.replace(\"positives\", \"B: positives\")\n",
    "df[\"method\"] = df[\"method\"].str.replace(\"full\", \"C: full\")\n",
    "\n",
    "df = df\\\n",
    "    .sort_values(by=[\"latent_size\", \"metric\"])\\\n",
    "    .groupby([\"method\", \"latent_size\", \"metric\"]).agg([\"mean\", \"std\"])\\\n",
    "\n",
    "df.columns = df.columns.to_flat_index()\n",
    "\n",
    "df = df.assign(val=lambda x: x[(\"value\", \"mean\")].round(4).apply(str) + \" ± \" + x[(\"value\", \"std\")].round(4).apply(str))\\\n",
    "    .drop([(\"value\", \"mean\"), (\"value\", \"std\")], axis=1)\\\n",
    "    .reset_index()\\\n",
    "    .pivot(index=[\"latent_size\", \"method\"], columns=\"metric\", values=\"val\")\n",
    "\n",
    "cols = [\"precision_at_1\", \"mean_average_precision\", \"recall_at_k\", \"auroc\", \"auprc\", \"ausc\", \"ece\", \"precision_at_1_expected\", \"mean_average_precision_expected\", \"recall_at_k_expected\"]\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9f1723a001831d523cd1876b56459768eb4c4c68543f3c23c216dc8ca1c484f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
